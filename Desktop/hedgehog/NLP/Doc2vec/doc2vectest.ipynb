{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# gensim modules\n",
    "from gensim import utils\n",
    "from gensim.models.doc2vec import LabeledSentence, TaggedLineDocument\n",
    "from gensim.models import Doc2Vec\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "\n",
    "# random\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame, Panel\n",
    "\n",
    "#allcomments=pd.read_csv('C:\\\\Users\\\\Raven.Raven-PC\\\\Desktop\\\\hedgehog\\\\moneycontrolbis\\\\allcommentstest.csv')\n",
    "#allcomments=pd.read_csv('C:\\\\Users\\\\Fitec\\\\Downloads\\\\allcommentstest.csv')\n",
    "allcomments=pd.read_csv('C:\\\\Users\\\\Fitec\\\\Desktop\\\\yahoofinance\\\\NewData\\\\DataCommentsYahoo.csv')\n",
    "justcomments=allcomments['Comments']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(justcomments[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fitec\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:17: DeprecationWarning: The unescape method is deprecated and will be removed in 3.5, use html.unescape() instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aether once again pushes the 3d printing sector sky high  incredible', 'almost sold my calls this morning good thing almost doesnt count', 'i just want ddd to get to 75 then i think ill take some profit', 'at drudgereport there is a good article about the 3d printer spacennmaybe the sector is getting hot again like years ago', 'its clear that the reseller surveys are telling a story of ddd winning out over ssys  this runup while certainly part shortsqueeze is based on something more  substantial  and since no deal has surfaced i dont think thats what is coming  a few more printers being sold leads to the increase eps at the materials marginsnnnothing about this runup is based on what has been happening more on what is improving', '6539 calls wu002fstrike at 20 been outstanding for a long time is shorty looking to scoop up 650000 and then drop them on the market', 'no risk no fun just went in will top up if it goes up to 25', 'the lack of participation in this rally by hpq suggests the run was more short squeeze than based on fundamental performance the folks who chased this above 20 are going to be scratching their heads wondering what happened when it drops to 1516  if it were a sector rally hpq would participate but hp doesnt have the short interest ddd has so it becomes obvious what is happening here games games and games when the music stops be sure you have a chair to fall into', 'this is crazy']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from html.parser import HTMLParser\n",
    "html_parser = HTMLParser()\n",
    "#test=\"I luv my &lt;3 iphone &amp; youâ€™re awsm apple. DisplayIsAwesome, sooo happppppy ðŸ™‚ http://www.apple.com\"\n",
    "#parsedtest=html_parser.unescape(test)\n",
    "#print(parsedtest)\n",
    "parsedcomments=[]\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "\n",
    "for i in justcomments:\n",
    "    #j= i.decode(\"utf8\").encode(\"ascii\",\"ignore\")\n",
    "    htmlparsedcomment = html_parser.unescape(str(i))\n",
    "    htmlparsedcomment=htmlparsedcomment.lower()\n",
    "    htmlparsedcomment = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', htmlparsedcomment, flags=re.MULTILINE)\n",
    "    htmlparsedcomment = re.sub(r'[^\\w\\s]','',htmlparsedcomment)\n",
    "    htmlparsedcomment=emoji_pattern.sub(r'', htmlparsedcomment)\n",
    "    htmlparsedcomment=re.sub(r'[^\\x00-\\x7f]',r'', htmlparsedcomment) \n",
    "    htmlparsedcomment=htmlparsedcomment.replace('\\n', '')\n",
    "    #s = s.encode('ascii',errors='ignore')\n",
    "    parsedcomments.append(htmlparsedcomment)\n",
    "    #Cleaning checkpoint 1 - To be explored\n",
    "print(parsedcomments[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "commentsfile=open('comments4.txt','w')\n",
    "for item in parsedcomments:\n",
    "    if item.rstrip():                 #this is only to remove blank lines if any in the text file \n",
    "        commentsfile.write(\"%s\\n\" % item)\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "timeformodel:0.0015859200002523721\n",
      "timeforbuildvocab:14.178272426666808\n",
      "timefortraintillnow:68.33685845333275\n",
      "timefortraintillnow:138.00302037333313\n",
      "timefortraintillnow:205.98682325333266\n",
      "timefortraintillnow:273.8067985066664\n",
      "timefortraintillnow:341.2111381333334\n",
      "timefortraintillnow:408.90608170666655\n",
      "timefortraintillnow:474.2509905066663\n",
      "timefortraintillnow:543.2719257600002\n",
      "timefortraintillnow:613.0832294399997\n",
      "timefortraintillnow:680.0454545066668\n",
      "20\n",
      "timeformodel:0.07694378666656121\n",
      "timeforbuildvocab:13.926432426666906\n",
      "timefortraintillnow:66.25986730666682\n",
      "timefortraintillnow:132.6492957866667\n",
      "timefortraintillnow:198.9069175466666\n",
      "timefortraintillnow:265.8340219733336\n",
      "timefortraintillnow:332.73209472000053\n",
      "timefortraintillnow:399.4692974933332\n",
      "timefortraintillnow:466.0077009066672\n",
      "timefortraintillnow:532.3983500800005\n",
      "timefortraintillnow:598.4977856000005\n",
      "timefortraintillnow:664.654827946667\n",
      "30\n",
      "timeformodel:0.08297429333379114\n",
      "timeforbuildvocab:13.94455679999919\n",
      "timefortraintillnow:66.5541614933336\n",
      "timefortraintillnow:133.29270485333382\n",
      "timefortraintillnow:200.40913578666732\n",
      "timefortraintillnow:267.49393450666685\n",
      "timefortraintillnow:334.74844501333337\n",
      "timefortraintillnow:402.03461034666725\n",
      "timefortraintillnow:468.80844458666706\n",
      "timefortraintillnow:535.7099165866675\n",
      "timefortraintillnow:602.4442444800006\n",
      "timefortraintillnow:669.132273066667\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32mC:\\Users\\Fitec\\Anaconda3\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fname_or_handle, separately, sep_limit, ignore, pickle_protocol)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0m_pickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname_or_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"saved %s object\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: file must have a 'write' attribute",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-e4982b3846b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"timefortraintillnow:\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoc3\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtoc2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'doc2veccomplexitytest'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdimsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[1;31m#model = Word2Vec.load(fname) - TO LOAD the MODEL\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[1;31m#w2v = dict(zip(model.wv.index2word, model.wv.syn0))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Fitec\\Anaconda3\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'syn0norm'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'table'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cum_table'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m     \u001b[0msave\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSaveLoad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Fitec\\Anaconda3\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fname_or_handle, separately, sep_limit, ignore, pickle_protocol)\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# `fname_or_handle` does not have write attribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             self._smart_save(fname_or_handle, separately, sep_limit, ignore,\n\u001b[0;32m--> 497\u001b[0;31m                              pickle_protocol=pickle_protocol)\n\u001b[0m\u001b[1;32m    498\u001b[0m \u001b[1;31m#endclass SaveLoad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Fitec\\Anaconda3\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36m_smart_save\u001b[0;34m(self, fname, separately, sep_limit, ignore, pickle_protocol)\u001b[0m\n\u001b[1;32m    367\u001b[0m                                        compress, subname)\n\u001b[1;32m    368\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m             \u001b[0mpickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[1;31m# restore attribs handled specially\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Fitec\\Anaconda3\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36mpickle\u001b[0;34m(obj, fname, protocol)\u001b[0m\n\u001b[1;32m    918\u001b[0m     \"\"\"\n\u001b[1;32m    919\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msmart_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfout\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# 'b' for binary, needed on Windows\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m         \u001b[0m_pickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from gensim import utils\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "# random\n",
    "from random import shuffle\n",
    "\n",
    "# classifier\n",
    "\n",
    "class LabeledLineSentence(object):\n",
    "    def __init__(self, sources):\n",
    "        self.sources = sources\n",
    "\n",
    "        flipped = {}\n",
    "\n",
    "        # make sure that keys are unique\n",
    "        for key, value in sources.items():\n",
    "            if value not in flipped:\n",
    "                flipped[value] = [key]\n",
    "            else:\n",
    "                raise Exception('Non-unique prefix encountered')\n",
    "\n",
    "    def __iter__(self):\n",
    "        for source, prefix in self.sources.items():\n",
    "            with utils.smart_open(source) as fin:\n",
    "                for item_no, line in enumerate(fin):\n",
    "                    yield LabeledSentence(utils.to_unicode(line).split(), [prefix + '_%s' % item_no])\n",
    "\n",
    "    def to_array(self):\n",
    "        self.sentences = []\n",
    "        for source, prefix in self.sources.items():\n",
    "            with utils.smart_open(source) as fin:\n",
    "                for item_no, line in enumerate(fin):\n",
    "                    self.sentences.append(LabeledSentence(utils.to_unicode(line).split(), [prefix + '_%s' % item_no]))\n",
    "        return self.sentences\n",
    "\n",
    "    def sentences_perm(self):\n",
    "        shuffle(self.sentences)\n",
    "        return self.sentences\n",
    "\n",
    "sources = {'comments4.txt' : 'DOCS'}\n",
    "sentences = LabeledLineSentence(sources)\n",
    "\n",
    "\n",
    "for dimsize in range(10,80,10):\n",
    "    print(str(dimsize))\n",
    "    tic = time.clock()\n",
    "\n",
    "    model = Doc2Vec(min_count=1, window=10, size=dimsize, sample=1e-4, negative=5, workers=8)\n",
    "\n",
    "    toc1= time.clock()\n",
    "    timeformodel=toc1-tic\n",
    "    print(\"timeformodel:\"+str(timeformodel))\n",
    "    model.build_vocab(sentences.to_array())\n",
    "    toc2= time.clock()\n",
    "    timeforbuildvocab=toc2-toc1\n",
    "    print(\"timeforbuildvocab:\"+str(timeforbuildvocab))\n",
    "    for epoch in range(10):\n",
    "\n",
    "        model.train(sentences.sentences_perm())\n",
    "        toc3= time.clock()\n",
    "        print(\"timefortraintillnow:\"+str(toc3-toc2))\n",
    "\n",
    "    model.save('doc2veccomplexitytest'+str(dimsize))\n",
    "#model = Word2Vec.load(fname) - TO LOAD the MODEL\n",
    "#w2v = dict(zip(model.wv.index2word, model.wv.syn0))\n",
    "#docvecs_np_array=np.toarray(model.docvecs)\n",
    "#print(docvecs_np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KMeans' object has no attribute 'docvecs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-0837050dced1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m#docvecs_np_array=np.toarray(model.docvecs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdocvecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoctag_syn0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'KMeans' object has no attribute 'docvecs'"
     ]
    }
   ],
   "source": [
    "#docvecs_np_array=np.toarray(model.docvecs)\n",
    "print(model.docvecs.doctag_syn0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=10,\n",
       "    n_clusters=2, n_init=1, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "X=model.docvecs.doctag_syn0\n",
    "true_k = 2\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=10, n_init=1)\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'vectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-342bac591bef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Top terms per cluster:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0morder_centroids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mterms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrue_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cluster %d:\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind]),\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "documents = TaggedLineDocument('comments4.txt')\n",
    "model = Doc2Vec(documents, size=10, window=8, min_count=5, workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Doc2Vec' object has no attribute 'syn0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-f659742e91df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msyn0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Doc2Vec' object has no attribute 'syn0'"
     ]
    }
   ],
   "source": [
    "print(model.syn0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('again', 0.9715061783790588),\n",
       " ('add', 0.9681113958358765),\n",
       " ('least', 0.9595438838005066),\n",
       " ('21', 0.9575897455215454),\n",
       " ('650', 0.9541219472885132),\n",
       " ('450', 0.9538404941558838),\n",
       " ('fly', 0.9531024694442749),\n",
       " ('rather', 0.9528695940971375),\n",
       " ('82', 0.9520964622497559),\n",
       " ('bounce', 0.9511395692825317)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('uc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12007, 10)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.docvecs.doctag_syn0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os\n",
    "import collections\n",
    "import smart_open\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def read_corpus(fname, tokens_only=False):\n",
    "    with smart_open.smart_open(fname, encoding=\"iso-8859-1\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if tokens_only:\n",
    "                yield gensim.utils.simple_preprocess(line)\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                yield gensim.models.doc2vec.TaggedDocument(gensim.utils.simple_preprocess(line), [i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datafile='comments4.txt'\n",
    "train_corpus = list(read_corpus(datafile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['srei', 'infra', 'who', 'financed', 'bikaner', 'suratgarh', 'rd', 'and', 'partner', 'of', 'mbl', 'infra', 'is', 'rising', 'so', 'mbl', 'infra', 'will', 'also', 'rise'], tags=[0]),\n",
       " TaggedDocument(words=['srei', 'infra', 'who', 'financed', 'bikaner', 'suratgarh', 'rd', 'and', 'partner', 'of', 'mbl', 'infra', 'is', 'rising', 'so', 'mbl', 'infra', 'will', 'also', 'rise'], tags=[1])]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpus[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(size=50, min_count=2, iter=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.build_vocab(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 27.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8357080"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time model.train(train_corpus, total_examples=model.corpus_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ranks = []\n",
    "second_ranks = []\n",
    "for doc_id in range(len(train_corpus)):\n",
    "    inferred_vector = model.infer_vector(train_corpus[doc_id].words)\n",
    "    sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "    \n",
    "    second_ranks.append(sims[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 2401,\n",
       "         1: 325,\n",
       "         2: 184,\n",
       "         3: 126,\n",
       "         4: 101,\n",
       "         5: 78,\n",
       "         6: 62,\n",
       "         7: 48,\n",
       "         8: 53,\n",
       "         9: 47,\n",
       "         10: 44,\n",
       "         11: 34,\n",
       "         12: 28,\n",
       "         13: 25,\n",
       "         14: 29,\n",
       "         15: 28,\n",
       "         16: 28,\n",
       "         17: 24,\n",
       "         18: 20,\n",
       "         19: 24,\n",
       "         20: 23,\n",
       "         21: 22,\n",
       "         22: 14,\n",
       "         23: 21,\n",
       "         24: 16,\n",
       "         25: 14,\n",
       "         26: 25,\n",
       "         27: 14,\n",
       "         28: 13,\n",
       "         29: 12,\n",
       "         30: 10,\n",
       "         31: 14,\n",
       "         32: 13,\n",
       "         33: 6,\n",
       "         34: 13,\n",
       "         35: 12,\n",
       "         36: 7,\n",
       "         37: 18,\n",
       "         38: 9,\n",
       "         39: 12,\n",
       "         40: 11,\n",
       "         41: 12,\n",
       "         42: 7,\n",
       "         43: 6,\n",
       "         44: 8,\n",
       "         45: 12,\n",
       "         46: 8,\n",
       "         48: 10,\n",
       "         49: 8,\n",
       "         50: 10,\n",
       "         51: 7,\n",
       "         52: 13,\n",
       "         53: 7,\n",
       "         54: 13,\n",
       "         55: 5,\n",
       "         56: 9,\n",
       "         57: 10,\n",
       "         58: 9,\n",
       "         59: 8,\n",
       "         60: 10,\n",
       "         61: 10,\n",
       "         62: 10,\n",
       "         63: 4,\n",
       "         64: 5,\n",
       "         65: 5,\n",
       "         66: 8,\n",
       "         67: 2,\n",
       "         68: 4,\n",
       "         69: 6,\n",
       "         70: 12,\n",
       "         71: 9,\n",
       "         72: 4,\n",
       "         73: 9,\n",
       "         74: 10,\n",
       "         75: 5,\n",
       "         76: 3,\n",
       "         77: 5,\n",
       "         78: 4,\n",
       "         79: 11,\n",
       "         80: 4,\n",
       "         81: 4,\n",
       "         82: 6,\n",
       "         83: 3,\n",
       "         84: 3,\n",
       "         85: 4,\n",
       "         86: 1,\n",
       "         87: 5,\n",
       "         88: 9,\n",
       "         89: 6,\n",
       "         90: 8,\n",
       "         91: 5,\n",
       "         92: 5,\n",
       "         93: 6,\n",
       "         94: 6,\n",
       "         95: 5,\n",
       "         96: 6,\n",
       "         97: 9,\n",
       "         98: 6,\n",
       "         99: 4,\n",
       "         100: 5,\n",
       "         101: 4,\n",
       "         102: 4,\n",
       "         103: 5,\n",
       "         104: 8,\n",
       "         105: 4,\n",
       "         106: 8,\n",
       "         107: 3,\n",
       "         108: 3,\n",
       "         109: 6,\n",
       "         110: 4,\n",
       "         111: 5,\n",
       "         112: 3,\n",
       "         113: 6,\n",
       "         114: 1,\n",
       "         115: 2,\n",
       "         116: 6,\n",
       "         117: 1,\n",
       "         118: 6,\n",
       "         119: 2,\n",
       "         120: 8,\n",
       "         121: 2,\n",
       "         122: 3,\n",
       "         123: 1,\n",
       "         124: 4,\n",
       "         125: 5,\n",
       "         126: 4,\n",
       "         127: 7,\n",
       "         128: 2,\n",
       "         129: 9,\n",
       "         130: 3,\n",
       "         131: 3,\n",
       "         132: 2,\n",
       "         133: 6,\n",
       "         134: 6,\n",
       "         135: 3,\n",
       "         136: 4,\n",
       "         137: 2,\n",
       "         138: 4,\n",
       "         139: 3,\n",
       "         140: 5,\n",
       "         141: 5,\n",
       "         142: 2,\n",
       "         143: 9,\n",
       "         144: 5,\n",
       "         146: 3,\n",
       "         147: 2,\n",
       "         148: 3,\n",
       "         149: 3,\n",
       "         150: 2,\n",
       "         151: 5,\n",
       "         152: 4,\n",
       "         153: 1,\n",
       "         154: 5,\n",
       "         155: 3,\n",
       "         156: 3,\n",
       "         157: 2,\n",
       "         158: 7,\n",
       "         159: 4,\n",
       "         160: 4,\n",
       "         162: 4,\n",
       "         163: 3,\n",
       "         164: 4,\n",
       "         165: 3,\n",
       "         166: 4,\n",
       "         167: 1,\n",
       "         168: 6,\n",
       "         169: 3,\n",
       "         170: 1,\n",
       "         171: 7,\n",
       "         172: 4,\n",
       "         173: 2,\n",
       "         174: 3,\n",
       "         175: 3,\n",
       "         176: 1,\n",
       "         177: 3,\n",
       "         178: 2,\n",
       "         179: 5,\n",
       "         180: 1,\n",
       "         181: 3,\n",
       "         182: 2,\n",
       "         183: 4,\n",
       "         184: 4,\n",
       "         185: 1,\n",
       "         186: 2,\n",
       "         187: 1,\n",
       "         188: 3,\n",
       "         189: 5,\n",
       "         190: 2,\n",
       "         191: 2,\n",
       "         192: 2,\n",
       "         193: 3,\n",
       "         194: 2,\n",
       "         195: 4,\n",
       "         197: 4,\n",
       "         198: 5,\n",
       "         199: 1,\n",
       "         200: 1,\n",
       "         201: 3,\n",
       "         202: 3,\n",
       "         203: 4,\n",
       "         204: 3,\n",
       "         206: 2,\n",
       "         207: 8,\n",
       "         208: 6,\n",
       "         209: 2,\n",
       "         210: 2,\n",
       "         211: 4,\n",
       "         212: 4,\n",
       "         213: 4,\n",
       "         214: 6,\n",
       "         215: 1,\n",
       "         216: 3,\n",
       "         217: 1,\n",
       "         218: 6,\n",
       "         219: 3,\n",
       "         220: 4,\n",
       "         221: 5,\n",
       "         222: 1,\n",
       "         223: 1,\n",
       "         224: 3,\n",
       "         225: 5,\n",
       "         226: 5,\n",
       "         227: 2,\n",
       "         228: 5,\n",
       "         229: 7,\n",
       "         230: 2,\n",
       "         231: 3,\n",
       "         232: 3,\n",
       "         233: 4,\n",
       "         234: 2,\n",
       "         235: 2,\n",
       "         236: 2,\n",
       "         237: 3,\n",
       "         238: 5,\n",
       "         239: 2,\n",
       "         241: 6,\n",
       "         242: 3,\n",
       "         243: 4,\n",
       "         244: 2,\n",
       "         245: 2,\n",
       "         246: 5,\n",
       "         247: 3,\n",
       "         248: 1,\n",
       "         249: 7,\n",
       "         250: 4,\n",
       "         251: 2,\n",
       "         252: 1,\n",
       "         253: 2,\n",
       "         254: 3,\n",
       "         255: 2,\n",
       "         256: 4,\n",
       "         257: 3,\n",
       "         258: 4,\n",
       "         259: 3,\n",
       "         260: 2,\n",
       "         261: 2,\n",
       "         262: 6,\n",
       "         263: 9,\n",
       "         264: 3,\n",
       "         265: 7,\n",
       "         266: 4,\n",
       "         267: 5,\n",
       "         268: 1,\n",
       "         269: 2,\n",
       "         270: 1,\n",
       "         271: 3,\n",
       "         272: 5,\n",
       "         273: 2,\n",
       "         274: 4,\n",
       "         275: 1,\n",
       "         276: 3,\n",
       "         277: 2,\n",
       "         278: 2,\n",
       "         279: 1,\n",
       "         280: 4,\n",
       "         281: 3,\n",
       "         282: 2,\n",
       "         283: 1,\n",
       "         284: 3,\n",
       "         285: 2,\n",
       "         287: 2,\n",
       "         288: 6,\n",
       "         289: 1,\n",
       "         290: 5,\n",
       "         291: 2,\n",
       "         292: 2,\n",
       "         293: 2,\n",
       "         294: 4,\n",
       "         295: 5,\n",
       "         296: 6,\n",
       "         297: 3,\n",
       "         298: 1,\n",
       "         299: 3,\n",
       "         300: 1,\n",
       "         301: 4,\n",
       "         302: 3,\n",
       "         303: 3,\n",
       "         304: 2,\n",
       "         305: 2,\n",
       "         306: 1,\n",
       "         307: 2,\n",
       "         308: 1,\n",
       "         309: 3,\n",
       "         310: 3,\n",
       "         312: 4,\n",
       "         313: 1,\n",
       "         315: 3,\n",
       "         317: 1,\n",
       "         318: 5,\n",
       "         319: 3,\n",
       "         320: 3,\n",
       "         321: 1,\n",
       "         322: 1,\n",
       "         323: 5,\n",
       "         324: 2,\n",
       "         325: 1,\n",
       "         326: 6,\n",
       "         327: 5,\n",
       "         329: 3,\n",
       "         330: 3,\n",
       "         331: 1,\n",
       "         332: 5,\n",
       "         333: 4,\n",
       "         334: 2,\n",
       "         335: 5,\n",
       "         337: 2,\n",
       "         338: 2,\n",
       "         339: 1,\n",
       "         340: 3,\n",
       "         341: 2,\n",
       "         342: 2,\n",
       "         343: 2,\n",
       "         344: 1,\n",
       "         345: 3,\n",
       "         346: 2,\n",
       "         347: 7,\n",
       "         348: 5,\n",
       "         349: 4,\n",
       "         350: 1,\n",
       "         351: 6,\n",
       "         352: 3,\n",
       "         353: 4,\n",
       "         354: 2,\n",
       "         355: 4,\n",
       "         356: 1,\n",
       "         357: 2,\n",
       "         358: 3,\n",
       "         359: 6,\n",
       "         360: 2,\n",
       "         361: 2,\n",
       "         362: 3,\n",
       "         363: 1,\n",
       "         364: 5,\n",
       "         366: 1,\n",
       "         367: 2,\n",
       "         368: 3,\n",
       "         369: 1,\n",
       "         370: 5,\n",
       "         371: 4,\n",
       "         372: 3,\n",
       "         373: 3,\n",
       "         374: 6,\n",
       "         375: 1,\n",
       "         376: 4,\n",
       "         377: 2,\n",
       "         378: 1,\n",
       "         379: 4,\n",
       "         381: 1,\n",
       "         382: 1,\n",
       "         383: 1,\n",
       "         384: 3,\n",
       "         385: 4,\n",
       "         386: 3,\n",
       "         388: 6,\n",
       "         389: 2,\n",
       "         390: 2,\n",
       "         391: 2,\n",
       "         393: 3,\n",
       "         395: 3,\n",
       "         396: 3,\n",
       "         397: 3,\n",
       "         398: 1,\n",
       "         399: 4,\n",
       "         400: 1,\n",
       "         401: 2,\n",
       "         402: 2,\n",
       "         403: 4,\n",
       "         404: 7,\n",
       "         405: 3,\n",
       "         406: 3,\n",
       "         407: 2,\n",
       "         408: 1,\n",
       "         409: 1,\n",
       "         410: 3,\n",
       "         411: 1,\n",
       "         412: 2,\n",
       "         413: 1,\n",
       "         414: 1,\n",
       "         416: 1,\n",
       "         417: 4,\n",
       "         419: 2,\n",
       "         420: 3,\n",
       "         422: 1,\n",
       "         423: 1,\n",
       "         424: 1,\n",
       "         425: 2,\n",
       "         426: 2,\n",
       "         427: 2,\n",
       "         428: 1,\n",
       "         429: 2,\n",
       "         431: 1,\n",
       "         432: 2,\n",
       "         433: 5,\n",
       "         435: 1,\n",
       "         436: 1,\n",
       "         437: 2,\n",
       "         438: 2,\n",
       "         439: 1,\n",
       "         440: 3,\n",
       "         441: 2,\n",
       "         442: 1,\n",
       "         443: 3,\n",
       "         444: 2,\n",
       "         445: 2,\n",
       "         446: 2,\n",
       "         447: 2,\n",
       "         449: 1,\n",
       "         450: 3,\n",
       "         451: 3,\n",
       "         452: 1,\n",
       "         453: 2,\n",
       "         454: 1,\n",
       "         455: 2,\n",
       "         456: 1,\n",
       "         457: 4,\n",
       "         458: 5,\n",
       "         459: 2,\n",
       "         460: 3,\n",
       "         461: 5,\n",
       "         462: 2,\n",
       "         463: 4,\n",
       "         464: 2,\n",
       "         465: 4,\n",
       "         467: 2,\n",
       "         468: 2,\n",
       "         469: 3,\n",
       "         470: 2,\n",
       "         471: 2,\n",
       "         472: 2,\n",
       "         473: 3,\n",
       "         474: 2,\n",
       "         475: 1,\n",
       "         476: 2,\n",
       "         477: 2,\n",
       "         478: 2,\n",
       "         479: 2,\n",
       "         480: 3,\n",
       "         482: 2,\n",
       "         483: 2,\n",
       "         484: 3,\n",
       "         485: 2,\n",
       "         486: 6,\n",
       "         487: 2,\n",
       "         488: 2,\n",
       "         489: 1,\n",
       "         490: 2,\n",
       "         491: 2,\n",
       "         492: 4,\n",
       "         493: 2,\n",
       "         494: 3,\n",
       "         496: 2,\n",
       "         498: 4,\n",
       "         499: 2,\n",
       "         500: 3,\n",
       "         502: 1,\n",
       "         503: 1,\n",
       "         504: 2,\n",
       "         505: 3,\n",
       "         506: 1,\n",
       "         508: 2,\n",
       "         509: 2,\n",
       "         510: 1,\n",
       "         511: 5,\n",
       "         512: 1,\n",
       "         513: 1,\n",
       "         514: 1,\n",
       "         515: 1,\n",
       "         516: 1,\n",
       "         517: 2,\n",
       "         518: 2,\n",
       "         519: 3,\n",
       "         520: 1,\n",
       "         522: 1,\n",
       "         524: 1,\n",
       "         525: 1,\n",
       "         527: 1,\n",
       "         528: 4,\n",
       "         529: 2,\n",
       "         530: 3,\n",
       "         531: 3,\n",
       "         532: 3,\n",
       "         534: 1,\n",
       "         535: 1,\n",
       "         536: 2,\n",
       "         537: 5,\n",
       "         538: 2,\n",
       "         539: 4,\n",
       "         540: 4,\n",
       "         541: 1,\n",
       "         542: 3,\n",
       "         543: 2,\n",
       "         544: 2,\n",
       "         545: 2,\n",
       "         546: 2,\n",
       "         548: 1,\n",
       "         549: 2,\n",
       "         550: 1,\n",
       "         552: 1,\n",
       "         553: 3,\n",
       "         554: 2,\n",
       "         555: 3,\n",
       "         556: 4,\n",
       "         557: 5,\n",
       "         558: 2,\n",
       "         559: 2,\n",
       "         560: 1,\n",
       "         561: 2,\n",
       "         562: 2,\n",
       "         563: 2,\n",
       "         564: 1,\n",
       "         565: 2,\n",
       "         567: 2,\n",
       "         569: 4,\n",
       "         570: 2,\n",
       "         571: 1,\n",
       "         572: 3,\n",
       "         573: 6,\n",
       "         574: 1,\n",
       "         575: 5,\n",
       "         577: 3,\n",
       "         578: 1,\n",
       "         579: 4,\n",
       "         580: 6,\n",
       "         581: 2,\n",
       "         582: 4,\n",
       "         583: 3,\n",
       "         584: 2,\n",
       "         585: 4,\n",
       "         588: 3,\n",
       "         589: 2,\n",
       "         590: 3,\n",
       "         591: 3,\n",
       "         592: 1,\n",
       "         593: 1,\n",
       "         594: 6,\n",
       "         595: 3,\n",
       "         596: 2,\n",
       "         597: 2,\n",
       "         598: 5,\n",
       "         600: 5,\n",
       "         601: 2,\n",
       "         602: 1,\n",
       "         603: 2,\n",
       "         604: 1,\n",
       "         605: 2,\n",
       "         606: 1,\n",
       "         607: 2,\n",
       "         608: 1,\n",
       "         609: 2,\n",
       "         611: 1,\n",
       "         612: 2,\n",
       "         613: 1,\n",
       "         614: 5,\n",
       "         615: 1,\n",
       "         616: 2,\n",
       "         617: 4,\n",
       "         618: 1,\n",
       "         619: 3,\n",
       "         620: 2,\n",
       "         621: 5,\n",
       "         622: 4,\n",
       "         623: 2,\n",
       "         624: 1,\n",
       "         625: 1,\n",
       "         627: 3,\n",
       "         628: 2,\n",
       "         629: 2,\n",
       "         630: 3,\n",
       "         631: 1,\n",
       "         632: 1,\n",
       "         633: 1,\n",
       "         634: 2,\n",
       "         635: 1,\n",
       "         637: 4,\n",
       "         638: 2,\n",
       "         639: 4,\n",
       "         640: 1,\n",
       "         641: 3,\n",
       "         642: 1,\n",
       "         644: 2,\n",
       "         645: 3,\n",
       "         646: 1,\n",
       "         648: 3,\n",
       "         650: 1,\n",
       "         651: 5,\n",
       "         652: 2,\n",
       "         653: 2,\n",
       "         654: 1,\n",
       "         655: 2,\n",
       "         656: 2,\n",
       "         657: 1,\n",
       "         658: 4,\n",
       "         660: 3,\n",
       "         661: 1,\n",
       "         662: 2,\n",
       "         663: 1,\n",
       "         664: 1,\n",
       "         666: 2,\n",
       "         667: 1,\n",
       "         668: 2,\n",
       "         669: 2,\n",
       "         670: 1,\n",
       "         672: 2,\n",
       "         673: 4,\n",
       "         674: 4,\n",
       "         675: 2,\n",
       "         677: 1,\n",
       "         678: 1,\n",
       "         679: 1,\n",
       "         680: 2,\n",
       "         681: 4,\n",
       "         682: 1,\n",
       "         683: 3,\n",
       "         684: 2,\n",
       "         685: 2,\n",
       "         687: 1,\n",
       "         689: 3,\n",
       "         690: 1,\n",
       "         691: 4,\n",
       "         692: 3,\n",
       "         693: 5,\n",
       "         694: 1,\n",
       "         695: 1,\n",
       "         697: 1,\n",
       "         699: 1,\n",
       "         700: 1,\n",
       "         701: 1,\n",
       "         702: 1,\n",
       "         703: 3,\n",
       "         704: 1,\n",
       "         705: 4,\n",
       "         706: 6,\n",
       "         708: 2,\n",
       "         709: 4,\n",
       "         710: 2,\n",
       "         711: 4,\n",
       "         712: 2,\n",
       "         713: 2,\n",
       "         714: 5,\n",
       "         715: 9,\n",
       "         716: 1,\n",
       "         717: 3,\n",
       "         718: 2,\n",
       "         719: 1,\n",
       "         720: 5,\n",
       "         721: 2,\n",
       "         722: 3,\n",
       "         723: 1,\n",
       "         724: 3,\n",
       "         725: 2,\n",
       "         726: 1,\n",
       "         727: 1,\n",
       "         728: 4,\n",
       "         729: 1,\n",
       "         730: 1,\n",
       "         731: 2,\n",
       "         732: 2,\n",
       "         733: 4,\n",
       "         734: 5,\n",
       "         735: 2,\n",
       "         736: 1,\n",
       "         737: 1,\n",
       "         738: 2,\n",
       "         739: 4,\n",
       "         740: 2,\n",
       "         741: 4,\n",
       "         742: 1,\n",
       "         743: 1,\n",
       "         744: 5,\n",
       "         745: 3,\n",
       "         747: 2,\n",
       "         748: 2,\n",
       "         749: 3,\n",
       "         750: 2,\n",
       "         752: 2,\n",
       "         753: 3,\n",
       "         756: 2,\n",
       "         757: 4,\n",
       "         758: 2,\n",
       "         759: 1,\n",
       "         760: 1,\n",
       "         761: 2,\n",
       "         762: 1,\n",
       "         763: 3,\n",
       "         764: 1,\n",
       "         765: 4,\n",
       "         766: 1,\n",
       "         767: 1,\n",
       "         768: 2,\n",
       "         769: 2,\n",
       "         770: 1,\n",
       "         771: 2,\n",
       "         773: 2,\n",
       "         774: 2,\n",
       "         775: 2,\n",
       "         776: 3,\n",
       "         777: 2,\n",
       "         778: 1,\n",
       "         779: 1,\n",
       "         780: 3,\n",
       "         781: 4,\n",
       "         783: 1,\n",
       "         784: 3,\n",
       "         785: 1,\n",
       "         786: 2,\n",
       "         787: 1,\n",
       "         788: 1,\n",
       "         789: 1,\n",
       "         790: 1,\n",
       "         791: 1,\n",
       "         792: 5,\n",
       "         793: 1,\n",
       "         794: 2,\n",
       "         795: 1,\n",
       "         796: 3,\n",
       "         797: 2,\n",
       "         798: 2,\n",
       "         799: 1,\n",
       "         800: 1,\n",
       "         802: 4,\n",
       "         803: 3,\n",
       "         804: 7,\n",
       "         805: 1,\n",
       "         807: 3,\n",
       "         808: 1,\n",
       "         809: 4,\n",
       "         810: 2,\n",
       "         811: 4,\n",
       "         812: 1,\n",
       "         813: 3,\n",
       "         814: 2,\n",
       "         815: 1,\n",
       "         816: 2,\n",
       "         817: 1,\n",
       "         818: 3,\n",
       "         819: 1,\n",
       "         820: 2,\n",
       "         821: 1,\n",
       "         822: 2,\n",
       "         823: 3,\n",
       "         824: 3,\n",
       "         825: 4,\n",
       "         826: 1,\n",
       "         827: 3,\n",
       "         828: 2,\n",
       "         830: 2,\n",
       "         832: 4,\n",
       "         833: 1,\n",
       "         834: 2,\n",
       "         835: 2,\n",
       "         836: 2,\n",
       "         838: 2,\n",
       "         839: 2,\n",
       "         840: 1,\n",
       "         842: 2,\n",
       "         843: 4,\n",
       "         844: 3,\n",
       "         846: 5,\n",
       "         847: 1,\n",
       "         848: 1,\n",
       "         849: 3,\n",
       "         850: 3,\n",
       "         853: 2,\n",
       "         855: 4,\n",
       "         856: 4,\n",
       "         857: 1,\n",
       "         858: 2,\n",
       "         859: 1,\n",
       "         860: 2,\n",
       "         861: 1,\n",
       "         863: 2,\n",
       "         864: 1,\n",
       "         865: 1,\n",
       "         867: 2,\n",
       "         868: 3,\n",
       "         869: 1,\n",
       "         870: 3,\n",
       "         871: 1,\n",
       "         872: 4,\n",
       "         873: 6,\n",
       "         874: 3,\n",
       "         875: 2,\n",
       "         876: 3,\n",
       "         877: 2,\n",
       "         878: 2,\n",
       "         879: 2,\n",
       "         880: 1,\n",
       "         881: 1,\n",
       "         884: 2,\n",
       "         886: 2,\n",
       "         887: 2,\n",
       "         888: 3,\n",
       "         890: 3,\n",
       "         892: 3,\n",
       "         893: 1,\n",
       "         894: 1,\n",
       "         895: 1,\n",
       "         896: 1,\n",
       "         899: 2,\n",
       "         900: 2,\n",
       "         901: 1,\n",
       "         902: 2,\n",
       "         903: 3,\n",
       "         904: 2,\n",
       "         905: 1,\n",
       "         906: 2,\n",
       "         907: 1,\n",
       "         908: 2,\n",
       "         909: 2,\n",
       "         910: 2,\n",
       "         911: 4,\n",
       "         912: 2,\n",
       "         913: 1,\n",
       "         914: 1,\n",
       "         915: 1,\n",
       "         916: 2,\n",
       "         917: 4,\n",
       "         918: 1,\n",
       "         919: 2,\n",
       "         920: 1,\n",
       "         921: 4,\n",
       "         922: 6,\n",
       "         923: 1,\n",
       "         924: 4,\n",
       "         925: 2,\n",
       "         927: 1,\n",
       "         928: 1,\n",
       "         929: 1,\n",
       "         930: 2,\n",
       "         931: 1,\n",
       "         932: 4,\n",
       "         933: 1,\n",
       "         934: 1,\n",
       "         935: 2,\n",
       "         936: 1,\n",
       "         937: 4,\n",
       "         938: 2,\n",
       "         939: 4,\n",
       "         940: 2,\n",
       "         941: 2,\n",
       "         942: 2,\n",
       "         943: 1,\n",
       "         944: 1,\n",
       "         945: 2,\n",
       "         946: 3,\n",
       "         947: 1,\n",
       "         948: 4,\n",
       "         949: 1,\n",
       "         951: 1,\n",
       "         953: 1,\n",
       "         954: 1,\n",
       "         955: 2,\n",
       "         956: 2,\n",
       "         957: 3,\n",
       "         958: 1,\n",
       "         959: 3,\n",
       "         960: 6,\n",
       "         961: 2,\n",
       "         962: 2,\n",
       "         963: 3,\n",
       "         964: 1,\n",
       "         965: 2,\n",
       "         966: 5,\n",
       "         967: 1,\n",
       "         969: 4,\n",
       "         970: 4,\n",
       "         971: 2,\n",
       "         972: 1,\n",
       "         973: 2,\n",
       "         974: 1,\n",
       "         975: 2,\n",
       "         976: 1,\n",
       "         977: 2,\n",
       "         978: 1,\n",
       "         979: 2,\n",
       "         980: 2,\n",
       "         981: 2,\n",
       "         982: 1,\n",
       "         983: 4,\n",
       "         984: 2,\n",
       "         987: 1,\n",
       "         988: 1,\n",
       "         989: 3,\n",
       "         990: 1,\n",
       "         991: 3,\n",
       "         993: 2,\n",
       "         994: 1,\n",
       "         995: 3,\n",
       "         996: 1,\n",
       "         997: 2,\n",
       "         998: 1,\n",
       "         999: 3,\n",
       "         1000: 2,\n",
       "         1001: 3,\n",
       "         1002: 1,\n",
       "         1003: 2,\n",
       "         1004: 2,\n",
       "         1007: 3,\n",
       "         1008: 1,\n",
       "         1009: 1,\n",
       "         1011: 2,\n",
       "         1012: 4,\n",
       "         1013: 1,\n",
       "         1014: 2,\n",
       "         1015: 2,\n",
       "         1016: 1,\n",
       "         1017: 1,\n",
       "         1018: 2,\n",
       "         1019: 1,\n",
       "         1020: 1,\n",
       "         1021: 2,\n",
       "         1022: 4,\n",
       "         1023: 2,\n",
       "         1024: 2,\n",
       "         1025: 1,\n",
       "         1026: 6,\n",
       "         1027: 3,\n",
       "         1029: 2,\n",
       "         1030: 1,\n",
       "         1031: 2,\n",
       "         1032: 1,\n",
       "         1033: 1,\n",
       "         1034: 2,\n",
       "         1035: 2,\n",
       "         1036: 1,\n",
       "         1037: 1,\n",
       "         1038: 2,\n",
       "         1039: 2,\n",
       "         1040: 1,\n",
       "         1041: 2,\n",
       "         1042: 2,\n",
       "         1043: 1,\n",
       "         1044: 2,\n",
       "         1045: 1,\n",
       "         1046: 1,\n",
       "         1047: 1,\n",
       "         1048: 4,\n",
       "         1049: 2,\n",
       "         1051: 2,\n",
       "         1052: 2,\n",
       "         1053: 6,\n",
       "         1054: 3,\n",
       "         1056: 2,\n",
       "         1057: 2,\n",
       "         1058: 3,\n",
       "         1059: 3,\n",
       "         1060: 3,\n",
       "         1061: 3,\n",
       "         1063: 3,\n",
       "         1064: 1,\n",
       "         1065: 4,\n",
       "         1066: 1,\n",
       "         1068: 1,\n",
       "         1069: 2,\n",
       "         1071: 2,\n",
       "         1073: 1,\n",
       "         1074: 1,\n",
       "         1075: 3,\n",
       "         1077: 1,\n",
       "         1078: 1,\n",
       "         1079: 3,\n",
       "         1080: 3,\n",
       "         1081: 1,\n",
       "         1082: 1,\n",
       "         1083: 1,\n",
       "         1084: 2,\n",
       "         1085: 1,\n",
       "         1086: 2,\n",
       "         1088: 1,\n",
       "         1089: 1,\n",
       "         1090: 2,\n",
       "         1092: 1,\n",
       "         1094: 2,\n",
       "         1095: 3,\n",
       "         1096: 4,\n",
       "         1097: 1,\n",
       "         1098: 1,\n",
       "         1099: 2,\n",
       "         1100: 1,\n",
       "         1102: 1,\n",
       "         ...})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Document (5017): Â«buy with target of stop loss ofÂ»\n",
      "\n",
      "Similar Document (4870, 0.9171402454376221): Â«news flash important update for all traders bsensemcx check urgently here googlzdatflÂ»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pick a random document from the test corpus and infer a vector from the model\n",
    "doc_id = random.randint(0, len(train_corpus))\n",
    "\n",
    "# Compare and print the most/median/least similar documents from the train corpus\n",
    "print('Train Document ({}): Â«{}Â»\\n'.format(doc_id, ' '.join(train_corpus[doc_id].words)))\n",
    "sim_id = second_ranks[doc_id]\n",
    "print('Similar Document {}: Â«{}Â»\\n'.format(sim_id, ' '.join(train_corpus[sim_id[0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "from gensim import utils\n",
    "def sentences_perm(self):\n",
    "    shuffle(self.sentences)\n",
    "    return self.sentences\n",
    "\n",
    "def to_array(self):\n",
    "    self.sentences = []\n",
    "    for source, prefix in self.sources.items():\n",
    "        with utils.smart_open(source) as fin:\n",
    "            for item_no, line in enumerate(fin):\n",
    "                self.sentences.append(LabeledSentence(utils.to_unicode(line).split(), [prefix + '_%s' % item_no]))\n",
    "    return self.sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
